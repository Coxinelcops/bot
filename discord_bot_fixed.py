import discord
from discord.ext import commands, tasks
import aiohttp
import asyncio
import os
from datetime import datetime, UTC
import logging
from threading import Thread
from flask import Flask
import re
from bs4 import BeautifulSoup
import json

# === Flask (pour Render) ===
app = Flask('')

@app.route('/')
def home():
    return "Bot Discord LoL Monitor actif."

def run_flask():
    port = int(os.environ.get('PORT', 5000))
    app.run(host='0.0.0.0', port=port)

# === Logger ===
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# === Bot Discord ===
intents = discord.Intents.default()
intents.message_content = True
intents.guilds = True
intents.reactions = True

bot = commands.Bot(command_prefix='!', intents=intents)
bot.ready_flag = False

# === Stockage des donn√©es ===
monitored_sites = {}
active_games = {}

class WebMonitor:
    def __init__(self):
        self.session = None
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
        }

    async def get_session(self):
        if not self.session:
            self.session = aiohttp.ClientSession(
                headers=self.headers,
                timeout=aiohttp.ClientTimeout(total=30)
            )
        return self.session

    async def check_site(self, url, selector=None):
        """V√©rifie un site pour des parties LoL en cours"""
        try:
            session = await self.get_session()
            async with session.get(url) as response:
                if response.status == 200:
                    html = await response.text()
                    return await self.detect_live_game(html, url)
                else:
                    logger.warning(f"Erreur HTTP {response.status} pour {url}")
                    return []
        except Exception as e:
            logger.error(f"Erreur lors de la v√©rification de {url}: {e}")
            return []

    async def detect_live_game(self, html, base_url):
        """D√©tection STRICTE - Ne d√©tecte que les vraies parties en cours"""
        try:
            soup = BeautifulSoup(html, 'html.parser')
            
            logger.info(f"üîç Analyse STRICTE de la page pour partie LIVE...")
            
            # √âTAPE 1: V√©rifications pr√©liminaires strictes
            if not soup or len(html.strip()) < 1000:
                logger.info("‚ùå Page trop courte ou vide - pas de partie live")
                return []
            
            page_text = soup.get_text().lower()
            
            # √âTAPE 2: V√©rifier les indicateurs N√âGATIFS (pas en jeu)
            negative_indicators = [
                'not in game', 'offline', 'last seen', 'not currently', 
                'not playing', 'idle', 'away', 'spectate match history',
                'match history', 'recent games', 'ranked stats only',
                'profile', 'statistics', 'no current game', 'not in a game'
            ]
            
            for negative in negative_indicators:
                if negative in page_text:
                    logger.info(f"‚ùå Indicateur n√©gatif d√©tect√©: '{negative}' - pas en jeu")
                    return []
            
            # √âTAPE 3: Chercher des indicateurs POSITIFS tr√®s sp√©cifiques
            live_indicators = await self.find_strict_live_indicators(soup, page_text)
            
            if not live_indicators:
                logger.info("‚ùå Aucun indicateur LIVE strict trouv√©")
                return []
            
            logger.info(f"‚úÖ {len(live_indicators)} indicateur(s) LIVE strict(s) trouv√©(s)")
            
            # √âTAPE 4: Validation finale avec extraction d'infos
            validated_games = []
            for indicator in live_indicators:
                game_info = await self.validate_and_extract_game_info(indicator, base_url, soup)
                if game_info:
                    logger.info(f"üéÆ Partie LIVE CONFIRM√âE: {game_info['title']}")
                    validated_games.append(game_info)
                    break  # Une seule partie suff√Æt
            
            return validated_games

        except Exception as e:
            logger.error(f"Erreur lors de la d√©tection live: {e}")
            return []

    async def find_live_games_alternative(self, soup, base_url):
        """M√©thode alternative ULTRA-STRICTE - derni√®re chance"""
        try:
            # Cette m√©thode ne sera appel√©e QUE si la d√©tection stricte √©choue
            # Et seulement avec des crit√®res TR√àS sp√©cifiques
            
            logger.info("üîç M√©thode alternative ultra-stricte...")
            
            # V√©rifier qu'on a bien du contenu
            if not soup or len(soup.get_text().strip()) < 500:
                logger.info("‚ùå Contenu insuffisant pour m√©thode alternative")
                return []
            
            page_text = soup.get_text().lower()
            
            # BLOQUER si on d√©tecte des √©l√©ments "non-live"
            blocking_terms = [
                'match history', 'recent games', 'past games', 'statistics only',
                'profile overview', 'not currently playing', 'offline', 'last seen',
                'ranked stats', 'champion mastery', 'achievements'
            ]
            
            for term in blocking_terms:
                if term in page_text:
                    logger.info(f"‚ùå Terme bloquant d√©tect√©: '{term}' - pas de partie live")
                    return []
            
            # Chercher des √©l√©ments TR√àS sp√©cifiques seulement
            specific_live_elements = soup.find_all(attrs={'data-live': True})
            specific_live_elements.extend(soup.find_all(attrs={'class': re.compile(r'live-game|current-game|in-game', re.I)}))
            
            if not specific_live_elements:
                logger.info("‚ùå Aucun √©l√©ment 'live' sp√©cifique trouv√©")
                return []
            
            # Si on arrive ici, on a trouv√© des √©l√©ments tr√®s sp√©cifiques
            logger.info(f"‚ö†Ô∏è  √âl√©ments sp√©cifiques d√©tect√©s, validation finale...")
            
            # Validation finale tr√®s stricte
            for element in specific_live_elements:
                element_text = element.get_text().lower()
                if 'live' in element_text or 'current' in element_text:
                    # V√©rifier qu'il n'y a pas de contexte n√©gatif
                    if not any(neg in element_text for neg in ['history', 'past', 'previous', 'last']):
                        player_name = await self.extract_player_name_from_url(base_url)
                        if player_name and player_name != "Joueur inconnu":
                            logger.info(f"üéÆ Partie alternative d√©tect√©e pour {player_name}")
                            return [{
                                'title': f"üî¥ Partie d√©tect√©e - {player_name}",
                                'url': base_url,
                                'player': player_name,
                                'status': "D√©tection alternative",
                                'type': 'alternative'
                            }]
            
            logger.info("‚ùå Validation finale √©chou√©e - pas de partie live")
            return []

        except Exception as e:
            logger.error(f"Erreur dans m√©thode alternative: {e}")
            return []

    async def find_strict_live_indicators(self, soup, page_text):
        """Trouve uniquement les indicateurs STRICTS de partie en cours"""
        live_indicators = []
        
        # 1. Chercher des √©l√©ments avec timer/countdown actif
        timers = soup.find_all(attrs={'class': re.compile(r'timer|countdown|duration', re.I)})
        for timer in timers:
            timer_text = timer.get_text().strip()
            # Format timer: "12:34" ou "1:23:45"
            if re.match(r'^\d{1,2}:\d{2}(:\d{2})?
    
    async def extract_player_name_from_url(self, url):
        """Extrait le nom du joueur depuis l'URL de fa√ßon plus robuste"""
        try:
            # Patterns courants pour extraire le nom du joueur
            patterns = [
                r'/summoner/([^/\?]+)',  # /summoner/PlayerName
                r'/player/([^/\?]+)',    # /player/PlayerName  
                r'/profile/([^/\?]+)',   # /profile/PlayerName
                r'summoner=([^&\?]+)',   # ?summoner=PlayerName
                r'player=([^&\?]+)',     # ?player=PlayerName
                r'name=([^&\?]+)',       # ?name=PlayerName
                r'/([^/\?]+)/?
, timer_text):
                live_indicators.append({'type': 'timer', 'element': timer, 'text': timer_text})
                logger.info(f"üéØ Timer actif d√©tect√©: {timer_text}")
        
        # 2. Chercher "IN GAME" ou "LIVE" tr√®s sp√©cifiques
        live_elements = soup.find_all(string=re.compile(r'\b(IN GAME|LIVE NOW|CURRENTLY PLAYING)\b', re.I))
        for element in live_elements:
            parent = element.parent if hasattr(element, 'parent') else None
            if parent and not self.is_static_content(parent):
                live_indicators.append({'type': 'status', 'element': parent, 'text': element.strip()})
                logger.info(f"üéØ Statut LIVE d√©tect√©: {element.strip()}")
        
        # 3. Chercher des boutons "Spectate" avec donn√©es de jeu
        spectate_buttons = soup.find_all(['button', 'a'], string=re.compile(r'spectate|watch', re.I))
        for button in spectate_buttons:
            # V√©rifier qu'il y a des donn√©es de champion/stats √† proximit√©
            parent_section = button.find_parent(['div', 'section'])
            if parent_section:
                section_text = parent_section.get_text().lower()
                if any(indicator in section_text for indicator in ['champion', 'kda', 'cs', 'level']):
                    # V√©rifier qu'il n'y a pas "history" ou "past"
                    if not any(negative in section_text for negative in ['history', 'past', 'previous', 'last game']):
                        live_indicators.append({'type': 'spectate', 'element': button, 'section': parent_section})
                        logger.info(f"üéØ Bouton spectate avec donn√©es live d√©tect√©")
        
        return live_indicators

    def is_static_content(self, element):
        """V√©rifie si l'√©l√©ment fait partie du contenu statique (navigation, footer, etc.)"""
        if not element:
            return True
            
        # V√©rifier les classes/IDs typiques du contenu statique
        static_patterns = [
            r'nav', r'menu', r'header', r'footer', r'sidebar', 
            r'banner', r'advertisement', r'promo', r'guide'
        ]
        
        element_classes = ' '.join(element.get('class', []))
        element_id = element.get('id', '')
        
        for pattern in static_patterns:
            if re.search(pattern, element_classes + ' ' + element_id, re.I):
                return True
                
        return False

    async def validate_and_extract_game_info(self, indicator, base_url, soup):
        """Valide un indicateur et extrait les informations de jeu"""
        try:
            if indicator['type'] == 'timer':
                # Pour un timer, chercher le contexte de jeu autour
                timer_element = indicator['element']
                game_context = timer_element.find_parent(['div', 'section'])
                
                if game_context:
                    context_text = game_context.get_text().lower()
                    if any(game_term in context_text for game_term in ['champion', 'rank', 'summoner']):
                        player_name = await self.extract_player_name_from_url(base_url)
                        return {
                            'title': f"üî¥ LIVE - {player_name} ({indicator['text']})",
                            'url': base_url,
                            'player': player_name,
                            'status': f"En jeu depuis {indicator['text']}",
                            'type': 'timer'
                        }
            
            elif indicator['type'] == 'status':
                player_name = await self.extract_player_name_from_url(base_url)
                return {
                    'title': f"üî¥ {indicator['text']} - {player_name}",
                    'url': base_url,
                    'player': player_name,
                    'status': indicator['text'],
                    'type': 'status'
                }
            
            elif indicator['type'] == 'spectate':
                # Extraire les infos depuis la section du bouton spectate
                section = indicator['section']
                section_text = section.get_text()
                
                # Chercher champion
                champion_match = re.search(r'champion[:\s]*(\w+)', section_text, re.I)
                champion = champion_match.group(1) if champion_match else "Inconnu"
                
                player_name = await self.extract_player_name_from_url(base_url)
                return {
                    'title': f"üî¥ SPECTATE - {player_name} ({champion})",
                    'url': base_url,
                    'player': player_name,
                    'champion': champion,
                    'status': "Spectatable",
                    'type': 'spectate'
                }
                
        except Exception as e:
            logger.error(f"Erreur validation indicateur: {e}")
            
        return None
    
    async def extract_player_name_from_url(self, url):
        """Extrait le nom du joueur depuis l'URL"""
        # Impl√©mentation √† compl√©ter
        return "Joueur inconnu"
         # Dernier segment de l'URL
            ]
            
            for pattern in patterns:
                match = re.search(pattern, url, re.I)
                if match:
                    player_name = match.group(1)
                    # Nettoyer le nom (d√©coder URL, supprimer caract√®res sp√©ciaux)
                    import urllib.parse
                    player_name = urllib.parse.unquote(player_name)
                    player_name = re.sub(r'[^\w\s-]', '', player_name).strip()
                    
                    # V√©rifier que ce n'est pas un terme g√©n√©rique
                    generic_terms = ['index', 'home', 'main', 'search', 'api', 'stats', 'leaderboard']
                    if player_name.lower() not in generic_terms and len(player_name) > 2:
                        logger.info(f"üéØ Nom du joueur extrait: {player_name}")
                        return player_name
            
            logger.warning(f"‚ö†Ô∏è Impossible d'extraire le nom du joueur depuis: {url}")
            return "Joueur inconnu"
            
        except Exception as e:
            logger.error(f"Erreur extraction nom joueur: {e}")
            return "Joueur inconnu"

# Fonction utilitaire pour debug - √† ajouter temporairement
monitor = WebMonitor()

async def debug_url(url):
    """Fonction de debug pour tester une URL"""
    logger.info(f"üêõ DEBUG: Test de {url}")
    
    try:
        session = await monitor.get_session()
        async with session.get(url) as response:
            if response.status == 200:
                html = await response.text()
                
                # Analyser le contenu
                soup = BeautifulSoup(html, 'html.parser')
                page_text = soup.get_text().lower()
                
                logger.info(f"üìÑ Taille de la page: {len(html)} caract√®res")
                logger.info(f"üìù Contient 'live': {'live' in page_text}")
                logger.info(f"üìù Contient 'in game': {'in game' in page_text}")
                logger.info(f"üìù Contient 'spectate': {'spectate' in page_text}")
                logger.info(f"üìù Contient 'offline': {'offline' in page_text}")
                logger.info(f"üìù Contient 'not playing': {'not playing' in page_text}")
                
                # Tester la d√©tection
                games = await monitor.detect_live_game(html, url)
                logger.info(f"üéÆ R√©sultat d√©tection: {len(games)} partie(s) d√©tect√©e(s)")
                
                for game in games:
                    logger.info(f"   - {game}")
                    
            else:
                logger.error(f"‚ùå Erreur HTTP {response.status}")
                
    except Exception as e:
        logger.error(f"‚ùå Erreur debug: {e}")

# Pour utiliser la fonction debug, ajoutez ceci dans votre bot:
# await debug_url("votre_url_ici")
, timer_text):
                live_indicators.append({'type': 'timer', 'element': timer, 'text': timer_text})
                logger.info(f"üéØ Timer actif d√©tect√©: {timer_text}")
        
        # 2. Chercher "IN GAME" ou "LIVE" tr√®s sp√©cifiques
        live_elements = soup.find_all(string=re.compile(r'\b(IN GAME|LIVE NOW|CURRENTLY PLAYING)\b', re.I))
        for element in live_elements:
            parent = element.parent if hasattr(element, 'parent') else None
            if parent and not self.is_static_content(parent):
                live_indicators.append({'type': 'status', 'element': parent, 'text': element.strip()})
                logger.info(f"üéØ Statut LIVE d√©tect√©: {element.strip()}")
        
        # 3. Chercher des boutons "Spectate" avec donn√©es de jeu
        spectate_buttons = soup.find_all(['button', 'a'], string=re.compile(r'spectate|watch', re.I))
        for button in spectate_buttons:
            # V√©rifier qu'il y a des donn√©es de champion/stats √† proximit√©
            parent_section = button.find_parent(['div', 'section'])
            if parent_section:
                section_text = parent_section.get_text().lower()
                if any(indicator in section_text for indicator in ['champion', 'kda', 'cs', 'level']):
                    # V√©rifier qu'il n'y a pas "history" ou "past"
                    if not any(negative in section_text for negative in ['history', 'past', 'previous', 'last game']):
                        live_indicators.append({'type': 'spectate', 'element': button, 'section': parent_section})
                        logger.info(f"üéØ Bouton spectate avec donn√©es live d√©tect√©")
        
        return live_indicators

    def is_static_content(self, element):
        """V√©rifie si l'√©l√©ment fait partie du contenu statique (navigation, footer, etc.)"""
        if not element:
            return True
            
        # V√©rifier les classes/IDs typiques du contenu statique
        static_patterns = [
            r'nav', r'menu', r'header', r'footer', r'sidebar', 
            r'banner', r'advertisement', r'promo', r'guide'
        ]
        
        element_classes = ' '.join(element.get('class', []))
        element_id = element.get('id', '')
        
        for pattern in static_patterns:
            if re.search(pattern, element_classes + ' ' + element_id, re.I):
                return True
                
        return False

    async def validate_and_extract_game_info(self, indicator, base_url, soup):
        """Valide un indicateur et extrait les informations de jeu"""
        try:
            if indicator['type'] == 'timer':
                # Pour un timer, chercher le contexte de jeu autour
                timer_element = indicator['element']
                game_context = timer_element.find_parent(['div', 'section'])
                
                if game_context:
                    context_text = game_context.get_text().lower()
                    if any(game_term in context_text for game_term in ['champion', 'rank', 'summoner']):
                        player_name = await self.extract_player_name_from_url(base_url)
                        return {
                            'title': f"üî¥ LIVE - {player_name} ({indicator['text']})",
                            'url': base_url,
                            'player': player_name,
                            'status': f"En jeu depuis {indicator['text']}",
                            'type': 'timer'
                        }
            
            elif indicator['type'] == 'status':
                player_name = await self.extract_player_name_from_url(base_url)
                return {
                    'title': f"üî¥ {indicator['text']} - {player_name}",
                    'url': base_url,
                    'player': player_name,
                    'status': indicator['text'],
                    'type': 'status'
                }
            
            elif indicator['type'] == 'spectate':
                # Extraire les infos depuis la section du bouton spectate
                section = indicator['section']
                section_text = section.get_text()
                
                # Chercher champion
                champion_match = re.search(r'champion[:\s]*(\w+)', section_text, re.I)
                champion = champion_match.group(1) if champion_match else "Inconnu"
                
                player_name = await self.extract_player_name_from_url(base_url)
                return {
                    'title': f"üî¥ SPECTATE - {player_name} ({champion})",
                    'url': base_url,
                    'player': player_name,
                    'champion': champion,
                    'status': "Spectatable",
                    'type': 'spectate'
                }
                
        except Exception as e:
            logger.error(f"Erreur validation indicateur: {e}")
            
        return None
    
    async def extract_player_name_from_url(self, url):
        """Extrait le nom du joueur depuis l'URL"""
        # Impl√©mentation √† compl√©ter
        return "Joueur inconnu"
